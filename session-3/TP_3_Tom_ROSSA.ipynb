{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fadd0f8df10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "              \n",
    "def dsigma(x):\n",
    "    return 1 - torch.pow(torch.tanh(x), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss (v,t):\n",
    "    return torch.sum(torch.pow(v-t,2)) \n",
    "\n",
    "def dloss(v,t):\n",
    "    return 2*(v-t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5529,  1.1427, -0.1610, -2.0885, -3.8716, -4.2020],\n",
       "        [ 1.1891,  2.0751,  4.8847,  1.2422, -1.4316, -4.5210],\n",
       "        [ 5.5198, -1.9320, -1.5009, -2.7508,  0.8101,  1.0077]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l = loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "w1 = torch.randn((784, 50))\n",
    "b1 = torch.randn((50,))\n",
    "w2 = torch.randn((50, 10))\n",
    "b2 = torch.randn((10,))\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(1427.7395, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "z1 = x1 @ w1 + b1\n",
    "h1 = sigma(z1)\n",
    "z2 = h1 @ w2 + b2\n",
    "h2 = z2\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1427.739501953125\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "dh2 = dloss(h2, y1) * dl\n",
    "cmp('h2',dh2,h2)\n",
    "dz2 = dh2\n",
    "cmp('z2',dz2, z2)\n",
    "dw2 = h1.t() @ dz2\n",
    "cmp('w2',dw2, w2)\n",
    "db2 = dz2.sum(axis=0, keepdim=True)\n",
    "cmp('b2',db2, b2)\n",
    "dh1 = dz2 @ w2.t()\n",
    "cmp('h1',dh1, h1)\n",
    "dz1 = dh1 * dsigma(z1)\n",
    "cmp('z1', dz1, z1)\n",
    "dw1 = x1.t() @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "db1 = dz1.sum(axis=0, keepdim=True)\n",
    "cmp('b1', db1, b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426.097900390625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    z1 = x @ w1 + b1\n",
    "    h1 = sigma(z1)\n",
    "    z2 = h1 @ w2 + b2\n",
    "    h2 = z2\n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = dloss(h2, y1) * dl\n",
    "    dz2 = dh2\n",
    "    dw2 = h1.t() @ dz2\n",
    "    db2 = dz2.sum(axis=0, keepdim=True)\n",
    "    dh1 = dz2 @ w2.t()\n",
    "    dz1 = dh1 * dsigma(z1)\n",
    "    dw1 = x1.t() @ dz1\n",
    "    db1 = dz1.sum(axis=0, keepdim=True)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 += -lr * db1.squeeze()\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2.squeeze()\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    w1 = torch.randn((784, 50))\n",
    "    b1 = torch.randn((50,)) \n",
    "    w2 = torch.randn((50, 10))\n",
    "    b2 = torch.randn((10,))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici pour éviter l'explosion de la loss, on joue sur le learning rate. S'il est trop grand au début du training, les losses explosent. On peut aussi tenter de prendre la moyenne au lieu de la somme pour la loss, ce que l'on ne fait pas ici. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "torch.set_printoptions(linewidth=200)\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        lsi = loss(h2, yb)\n",
    "        # backward\n",
    "        dw1, db1, dw2, db2 = backward(w1, b1, w2, b2, xb, yb, h2, z2, h1, z1)\n",
    "        # update\n",
    "        lr = 0.01 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "        #print(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 408477.25\n",
      "step = 100, loss = 28828.1171875\n",
      "step = 200, loss = 10713.1572265625\n",
      "step = 300, loss = 5308.1796875\n",
      "step = 400, loss = 3081.2294921875\n",
      "step = 500, loss = 1995.146484375\n",
      "step = 600, loss = 1405.490234375\n",
      "step = 700, loss = 1065.2857666015625\n",
      "step = 800, loss = 855.6450805664062\n",
      "step = 900, loss = 722.3392333984375\n",
      "step = 1000, loss = 633.9442749023438\n",
      "step = 1100, loss = 573.2753295898438\n",
      "step = 1200, loss = 530.39990234375\n",
      "step = 1300, loss = 499.17767333984375\n",
      "step = 1400, loss = 475.38043212890625\n",
      "step = 1500, loss = 452.91680908203125\n",
      "step = 1600, loss = 438.9681701660156\n",
      "step = 1700, loss = 428.1716003417969\n",
      "step = 1800, loss = 419.29779052734375\n",
      "step = 1900, loss = 412.4455871582031\n",
      "step = 2000, loss = 406.98651123046875\n",
      "step = 2100, loss = 402.4430236816406\n",
      "step = 2200, loss = 398.5719909667969\n",
      "step = 2300, loss = 395.2218017578125\n",
      "step = 2400, loss = 392.28643798828125\n",
      "step = 2500, loss = 389.687744140625\n",
      "step = 2600, loss = 387.36614990234375\n",
      "step = 2700, loss = 385.27508544921875\n",
      "step = 2800, loss = 383.3778991699219\n",
      "step = 2900, loss = 381.64495849609375\n",
      "step = 3000, loss = 380.05267333984375\n",
      "step = 3100, loss = 378.5820617675781\n",
      "step = 3200, loss = 377.2176513671875\n",
      "step = 3300, loss = 375.9474182128906\n",
      "step = 3400, loss = 374.76092529296875\n",
      "step = 3500, loss = 373.64984130859375\n",
      "step = 3600, loss = 372.60675048828125\n",
      "step = 3700, loss = 371.6251220703125\n",
      "step = 3800, loss = 370.6990661621094\n",
      "step = 3900, loss = 369.8230895996094\n",
      "step = 4000, loss = 368.9923400878906\n",
      "step = 4100, loss = 368.20233154296875\n",
      "step = 4200, loss = 367.4488525390625\n",
      "step = 4300, loss = 366.72833251953125\n",
      "step = 4400, loss = 366.0373229980469\n",
      "step = 4500, loss = 365.3728332519531\n",
      "step = 4600, loss = 364.7322692871094\n",
      "step = 4700, loss = 364.11328125\n",
      "step = 4800, loss = 363.5140380859375\n",
      "step = 4900, loss = 362.9327392578125\n",
      "step = 5000, loss = 362.3685607910156\n",
      "step = 5100, loss = 361.8204345703125\n",
      "step = 5200, loss = 361.28765869140625\n",
      "step = 5300, loss = 360.76934814453125\n",
      "step = 5400, loss = 360.26458740234375\n",
      "step = 5500, loss = 359.7723083496094\n",
      "step = 5600, loss = 359.2915954589844\n",
      "step = 5700, loss = 358.8216247558594\n",
      "step = 5800, loss = 358.361328125\n",
      "step = 5900, loss = 357.91015625\n",
      "step = 6000, loss = 357.467529296875\n",
      "step = 6100, loss = 357.03314208984375\n",
      "step = 6200, loss = 356.60662841796875\n",
      "step = 6300, loss = 356.1878356933594\n",
      "step = 6400, loss = 355.7765808105469\n",
      "step = 6500, loss = 355.372802734375\n",
      "step = 6600, loss = 354.9764099121094\n",
      "step = 6700, loss = 354.5873107910156\n",
      "step = 6800, loss = 354.2052001953125\n",
      "step = 6900, loss = 353.8299255371094\n",
      "step = 7000, loss = 353.4610595703125\n",
      "step = 7100, loss = 353.09832763671875\n",
      "step = 7200, loss = 352.7410583496094\n",
      "step = 7300, loss = 352.38885498046875\n",
      "step = 7400, loss = 352.041015625\n",
      "step = 7500, loss = 351.6968994140625\n",
      "step = 7600, loss = 351.355712890625\n",
      "step = 7700, loss = 351.0170593261719\n",
      "step = 7800, loss = 350.68072509765625\n",
      "step = 7900, loss = 350.3470764160156\n",
      "step = 8000, loss = 350.01727294921875\n",
      "step = 8100, loss = 349.6923522949219\n",
      "step = 8200, loss = 349.37322998046875\n",
      "step = 8300, loss = 349.0599365234375\n",
      "step = 8400, loss = 348.7524719238281\n",
      "step = 8500, loss = 348.45037841796875\n",
      "step = 8600, loss = 348.1531677246094\n",
      "step = 8700, loss = 347.86065673828125\n",
      "step = 8800, loss = 347.5723571777344\n",
      "step = 8900, loss = 347.2881774902344\n",
      "step = 9000, loss = 347.0080261230469\n",
      "step = 9100, loss = 346.731689453125\n",
      "step = 9200, loss = 346.4591064453125\n",
      "step = 9300, loss = 346.1902770996094\n",
      "step = 9400, loss = 345.9248962402344\n",
      "step = 9500, loss = 345.662841796875\n",
      "step = 9600, loss = 345.4040222167969\n",
      "step = 9700, loss = 345.1481018066406\n",
      "step = 9800, loss = 344.8949890136719\n",
      "step = 9900, loss = 344.64453125\n",
      "train_accuracy=0.7699999809265137\n",
      "test_accuracy=0.5860000252723694\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi[10:], label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a pris le même learning rate que précédemment pour éviter l'explosion des losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.01 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 489977.375\n",
      "step = 100, loss = 29850.802734375\n",
      "step = 200, loss = 10369.3330078125\n",
      "step = 300, loss = 4731.6904296875\n",
      "step = 400, loss = 2535.48095703125\n",
      "step = 500, loss = 1543.9052734375\n",
      "step = 600, loss = 1063.3631591796875\n",
      "step = 700, loss = 810.9407958984375\n",
      "step = 800, loss = 669.3974609375\n",
      "step = 900, loss = 585.3501586914062\n",
      "step = 1000, loss = 532.712646484375\n",
      "step = 1100, loss = 498.0165100097656\n",
      "step = 1200, loss = 473.98046875\n",
      "step = 1300, loss = 456.5047607421875\n",
      "step = 1400, loss = 443.1932067871094\n",
      "step = 1500, loss = 432.6089172363281\n",
      "step = 1600, loss = 423.8834533691406\n",
      "step = 1700, loss = 416.3723449707031\n",
      "step = 1800, loss = 409.4836730957031\n",
      "step = 1900, loss = 403.72210693359375\n",
      "step = 2000, loss = 398.6879577636719\n",
      "step = 2100, loss = 394.253662109375\n",
      "step = 2200, loss = 390.3627014160156\n",
      "step = 2300, loss = 386.8446350097656\n",
      "step = 2400, loss = 383.6231689453125\n",
      "step = 2500, loss = 380.64825439453125\n",
      "step = 2600, loss = 377.8819885253906\n",
      "step = 2700, loss = 375.29449462890625\n",
      "step = 2800, loss = 372.862548828125\n",
      "step = 2900, loss = 370.5682678222656\n",
      "step = 3000, loss = 368.398193359375\n",
      "step = 3100, loss = 366.3431396484375\n",
      "step = 3200, loss = 364.3966979980469\n",
      "step = 3300, loss = 362.5528259277344\n",
      "step = 3400, loss = 360.80584716796875\n",
      "step = 3500, loss = 359.15008544921875\n",
      "step = 3600, loss = 357.5798034667969\n",
      "step = 3700, loss = 356.0898742675781\n",
      "step = 3800, loss = 354.6752014160156\n",
      "step = 3900, loss = 353.33099365234375\n",
      "step = 4000, loss = 352.0526123046875\n",
      "step = 4100, loss = 350.83551025390625\n",
      "step = 4200, loss = 349.6755065917969\n",
      "step = 4300, loss = 348.5684814453125\n",
      "step = 4400, loss = 347.51068115234375\n",
      "step = 4500, loss = 346.4987487792969\n",
      "step = 4600, loss = 345.52947998046875\n",
      "step = 4700, loss = 344.6001281738281\n",
      "step = 4800, loss = 343.7081604003906\n",
      "step = 4900, loss = 342.85125732421875\n",
      "step = 5000, loss = 342.0272216796875\n",
      "step = 5100, loss = 341.2342529296875\n",
      "step = 5200, loss = 340.4706115722656\n",
      "step = 5300, loss = 339.734619140625\n",
      "step = 5400, loss = 339.0245361328125\n",
      "step = 5500, loss = 338.33856201171875\n",
      "step = 5600, loss = 337.67510986328125\n",
      "step = 5700, loss = 337.0322265625\n",
      "step = 5800, loss = 336.4083251953125\n",
      "step = 5900, loss = 335.8020324707031\n",
      "step = 6000, loss = 335.21185302734375\n",
      "step = 6100, loss = 334.63665771484375\n",
      "step = 6200, loss = 334.0757141113281\n",
      "step = 6300, loss = 333.5284423828125\n",
      "step = 6400, loss = 332.9945373535156\n",
      "step = 6500, loss = 332.47406005859375\n",
      "step = 6600, loss = 331.967041015625\n",
      "step = 6700, loss = 331.4735107421875\n",
      "step = 6800, loss = 330.9932861328125\n",
      "step = 6900, loss = 330.526123046875\n",
      "step = 7000, loss = 330.07135009765625\n",
      "step = 7100, loss = 329.6278076171875\n",
      "step = 7200, loss = 329.1944885253906\n",
      "step = 7300, loss = 328.7695617675781\n",
      "step = 7400, loss = 328.3516540527344\n",
      "step = 7500, loss = 327.93994140625\n",
      "step = 7600, loss = 327.53448486328125\n",
      "step = 7700, loss = 327.13623046875\n",
      "step = 7800, loss = 326.7465515136719\n",
      "step = 7900, loss = 326.3656311035156\n",
      "step = 8000, loss = 325.9929504394531\n",
      "step = 8100, loss = 325.627685546875\n",
      "step = 8200, loss = 325.2687683105469\n",
      "step = 8300, loss = 324.915771484375\n",
      "step = 8400, loss = 324.56842041015625\n",
      "step = 8500, loss = 324.22686767578125\n",
      "step = 8600, loss = 323.8912048339844\n",
      "step = 8700, loss = 323.56146240234375\n",
      "step = 8800, loss = 323.2377624511719\n",
      "step = 8900, loss = 322.9201354980469\n",
      "step = 9000, loss = 322.6084899902344\n",
      "step = 9100, loss = 322.3028259277344\n",
      "step = 9200, loss = 322.0030212402344\n",
      "step = 9300, loss = 321.7089538574219\n",
      "step = 9400, loss = 321.4203796386719\n",
      "step = 9500, loss = 321.1370849609375\n",
      "step = 9600, loss = 320.8583679199219\n",
      "step = 9700, loss = 320.5836181640625\n",
      "step = 9800, loss = 320.31207275390625\n",
      "step = 9900, loss = 320.0427551269531\n",
      "train_accuracy=0.7950000166893005\n",
      "test_accuracy=0.546999990940094\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi, label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden),  \n",
    "            nn.Tanh(),                 \n",
    "            nn.Linear(n_hidden, n_out)  \n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) \n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.14508\taccuracy (train, test): 0.05600\t0.10300\n",
      "step =   1000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.87600\n",
      "step =   2000\tloss=0.00000\taccuracy (train, test): 1.00000\t0.88100\n",
      "step =   3000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.88200\n",
      "step =   4000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.88200\n",
      "step =   5000\tloss=0.00000\taccuracy (train, test): 1.00000\t0.88300\n",
      "step =   6000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.88200\n",
      "step =   7000\tloss=0.00009\taccuracy (train, test): 1.00000\t0.88000\n",
      "step =   8000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.87800\n",
      "step =   9000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.87400\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!\n",
    "\n",
    "Pour cette exercice, on réalise unE série de modifications par rapport au précédent MLP en espérant améliorer l'accuracy du modèle sur le dataset de test. L'accuracy du train étant déjà à 1 et celle du test déjà très élevée, nous allons voir si on peut faire mieux. \n",
    "\n",
    "Tout d'abord, on modifie les fonctions d'activation en prenant des fonctions ReLU. On ajoute également une couche cachée au réseau. On modifie également la fonction de perte, en sélectionnant la cross entropy loss, censée être mieux adapter à la classification.\n",
    "\n",
    "Enfin, on utilise la méthode de Pytorch \"lr_scheduler\" qui adapte le learning rate au cours de l'entraînement et est censé améliorer la vitesse de convergence et donc de l'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler ## import the scheduler qui permet de mieux choisir le learning rate\n",
    "\n",
    "class MLP_upgrade(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),  \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out)  \n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) \n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP_upgrade()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=1.86197\taccuracy (train, test): 0.11500\t0.39900\n",
      "step =   1000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.85100\n",
      "step =   2000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.85200\n",
      "step =   3000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.85300\n",
      "step =   4000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.85600\n",
      "step =   5000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.85700\n",
      "step =   6000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86500\n",
      "step =   7000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86100\n",
      "step =   8000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86500\n",
      "step =   9000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86600\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step() # learning rate update à chaque epoch\n",
    "    \n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque, que l'accuracy de notre précédent réseau est légèrement moins bonne que précédemment. On tente ainsi d'ajouter du dropout dans le réseau pour voir si cela permet effectivement de mieux généraliser, et atteindre une meilleure accuracy out of sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_upgrade_drop(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # 20% de dropout, choisi arbitrairement \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out)\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) \n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP_upgrade_drop()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=1.87914\taccuracy (train, test): 0.07300\t0.29800\n",
      "step =   1000\tloss=0.00006\taccuracy (train, test): 1.00000\t0.85700\n",
      "step =   2000\tloss=0.00006\taccuracy (train, test): 1.00000\t0.86300\n",
      "step =   3000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.86100\n",
      "step =   4000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86000\n",
      "step =   5000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.86900\n",
      "step =   6000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.86500\n",
      "step =   7000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.87700\n",
      "step =   8000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.88400\n",
      "step =   9000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.88000\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step() # learning rate update à chaque epoch\n",
    "    \n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On atteint des performance très légèrement meilleures que le premier réseau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
